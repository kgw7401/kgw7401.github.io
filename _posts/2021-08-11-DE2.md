---
title: "데이터 엔지니어링(2) - 빅데이터 이해하기"
excerpt: ""

categories:
  - Data Engineering
tags:
  - 데이터 엔지니어링 기초
toc: true
toc_label: "목차"
---

# 빅데이터 이해하기

## 빅데이터의 개념

빅데이터라는 산업은 날이 가면 갈수록 성장하고 있다. 예전에는 그저 빅데이터 세상이 될 것이다라고 생각만 했지만 이제 우리는 정말로 빅데이터 세상에 살고 있는 것이다. 4차 산업혁명은 인공지능, 사물인터넷, 무인자동차 등 다양한 산업이 발전하고 있는데, 이를 기반으로 하는 것이 바로 '빅데이터'이다.

<img src="https://drive.google.com/uc?export=view&id=1XvAd0Y2U-XBkbVawDoGY7pLnkRYxzCQQ">

빅데이터는 단지 과거의 데이터가 아니라 기술, 분석, 통찰력까지 총칭하는 용어로 사용되고 있다. 다양한 정의가 있지만 그 중 가장 잘 알려지고 명확한 정의는 **6V**이다.

<img src="https://drive.google.com/uc?export=view&id=1mbMhkFFu5521d4FHKIWtxrRshGEKqK26">

위 그림이 너무 명확하게 정의되어 있는데, 책에서 이를 글로 잘 풀어 설명해주었다.

> 방대한 크기(Volume)의 다양한(Varity) 데이터들이 빠른 속도(Velocity)로 발생하고 있다. 빅데이터는 3V를 수용하며, 데이터의 진실성(Veracity)을 확보하고, 분석 데이터를 시각화(Visualization)함으로써 새로운 가치(Value)를 창출하는 것이다.

## 빅데이터의 목적

성공적인 빅데이터 시스템 구축과 운영을 위해서는 **사람, 기술, 데이터** 삼 박자가 잘 맞아떨어져야 한다. 그리고 이를 통해 인사이트를 발견하여, **비용 절감, 수익 창출, 문제 해결**을 하여 빅데이터의 최종 목적을 달성한다.

## 빅데이터의 활용

<img src="https://drive.google.com/uc?export=view&id=1G7Aar0SIFiU5MGzlGK2Ka4jKE7w_V8i9">

3V 데이터를 빅데이터 레이크나 웨어하우스에 저장하고, 이를 다시 진실성을 담은 빅데이터 마트로 구성한다. 분석가들은 이 빅데이터 마트를 활용해 인사이트를 얻고 가치 창출까지 진행한다.

## 빅데이터 프로젝트

빅데이터 프로젝트는 크게 플랫폼 구축형 프로젝트, 빅데이터 분석 프로젝트, 빅데이터 운영 프로젝트로 구성되어 있다. 각각을 간단하게 살펴보도록 하자.

먼저 플랫폼 구축형 프로젝트는 빅데이터의 하드웨어와 소프트웨어를 설치 및 구성하고 빅데이터의 기본 프로세스인 수집 -> 적재 -> 처리 -> 탐색 -> 분석의 기능을 구성한다. 간단히 빅데이터 준비단계라고 할 수 있다.

빅데이터 분석 프로젝트는 말 그대로 본격적인 빅데이터 분석 작업으로 데이터 분석과 데이터 엔지니어링, 비즈니스가 협업을 통해 정보의 탐색과 발견에 집중하여 이해와 기술이 성숙해졌을 때 가치를 창출하는 것을 말한다.

마지막으로 빅데이터 운영 프로젝트는 완성된 빅데이터 시스템을 중장기적으로 유지 관리하는 것으로, 다양한 기술적 이슈와 장애 발생을 해결하고 H/W, S/W 업그레이드 및 패치 작업을 진행한다.

## 빅데이터 구현기술

<img src="https://drive.google.com/uc?export=view&id=1BYPigcqt9aA4UJfNJijcmqnaIFE28reB">

빅데이터는 보통 위와 같은 구축 순서를 가진다. 하나하나 살펴보도록 하자.

### 수집 기술

먼저 수집 기술은 다양한 시스템으로부터 원천 데이터를 효과적으로 수집하는 기술이다. 데이터는 데이터베이스, 파일, API, 메세지 등 다양한 인터페이스 유형과 연결되어 정형 또는 비정형 데이터를 대용량으로 수집할 수 있다. 

수집 처리는 **대용량 파일 수집**과 **실시간 스트림 수집**으로 나눌 수 있는데, 실시간 수집의 경우 CEP(Complex Event Processing), ESP(Event Stream Processing) 기술이 적용되어 빠른 후속 처리를 수행한다.

관련 소프트웨어로는 Flume, Flunted, Scribe, Logstash, Chunkwa, NiFi, Embulk 등이 있다. 또한 실시간 처리를 위해 스톰과 에스퍼도 사용한다. 

- 역할: 내외부 데이터 연동 및 통합
- 활용 기술: 크롤링, FTP, API, RSS, Log 및 DB Aggregation, 스트리밍

### 적재 기술

적재 기술은 수집한 데이터를 분산 스토리지에 영구 또는 임시로 적재하는 기술이다. 빅데이터 분산 저장소는 크게 4가지가 있다. 

- HDFS: 대용량 파일을 영구적으로 저장
- NoSQL: 대규모 메시징 데이터 전체를 영구적으로 저장 (HBase, MongoDB, Casandra)
- 인메모리 캐시: 대규모 메시징 데이터 일부만 임시 저장(Redis, Memcached)
- Message Oriented Middleware(MOM): 대규모 메시징 데이터 전체를 버퍼링 처리(Kafka, RabbitMQ)

- 역할: 대용량/실시간 데이터 처리 및 분산 파일 시스템 저장
- 활용 기술: HDFS, NoSQL, 인메모리 캐시, Message Oriented Middleware

### 처리/탐색 기술

처리/탐색 기술은 대용량 저장소에 적재된 데이터를 분석에 활용하기 위해 데이터를 정형화 및 정규화하는 기술이다.

탐색적 분석에는 주로 SQL on Hadoop이 사용되며, 대화형 애드훅 쿼리로 데이터 변환 작업을 수행한다. 특히 정형/비정형 데이터를 결합해 기존에 기술적 한계로 만들지 못했던 새로운 데이터셋을 생성하는 중요한 작업이 진행되기도 한다. 또한 정기적으로 발생하는 처리/탐색 과정들은 워크폴로로 프로세스화해서 자동화시킨다.

처리/탐색 관련 기술로는 Hue, Hive, Spark 등이 있고, 자동화 워크플로우에는 AirFlow, Oozie 등이 있다.

- 역할: 데이터 선택, 변환, 워크플로 자동화 및 대화형 데이터 질의, 탐색적 Ad-Hoc 분석
- 활용 기술: 워크플로우, 스케줄러, SQL Like, Exploration Visualization

### 분석/응용 기술

분석 기술은 대규모 데이터로부터 패턴을 찾고, 그 패턴을 해석해서 통찰력을 확보하기 위한 기술이다. 활용 영역에 따라 통계, 데이터 마이닝, 텍스트 마이닝, 소셜 미디어 분석, 머신러닝 등 다양하게 분류된다. 

관련 기술로는 Impala, Zepplin, Mahout, R, Tensorflow 등이 있고, Sqoop을 응용해서 외부 RDBMS에 데이터를 제공할 수 있다.

## 빅데이터와 보안

### 데이터 보안

데이터 보안은 개인과 기업의 정보보호를 위한 정책과 기술을 말한다. 개인정보보호법은 빅데이터의 발전과 트레이드오프 관계를 이루고 있어 이를 적절히 지키며 데이터를 활용해야 하는데, 비식별화 기술을 통해 이러한 문제를 해결한다. 이 기술을 통해 우리는 개인을 특정할 수 없게되고 안전하게 사생활을 보호할 수 있다.

하지만 여기서도 몇 가지 문제가 있다. 첫번째는 재식별화이다. 빅데이터는 워낙 다양한 데이터들이 있기 때문에 아무리 비식별화를 진행해도 여러 데이터들이 결합되면서 점점 개인을 식별할 수 있게 되는 것이다. 두번째는 개인정보 보호로 인해 개인화된 서비스 또는 마케팅이 어려워진다는 점이다. 아무래도 고유값들이 비식별화되어 있다보면 타깃 분석과 서비스 개발이 쉽지가 않다. 이를 보완하기 위해 시스템에서 대체키를 발급하거나 최대한 짧은 주기로 데이터를 수집해 활용하는 방법을 사용한다.

### 접근제어 보안

빅데이터 시스템의 접근제어(인증, 권한)를 완벽하게 처리하는 데는 많은 어려움이 있다. 이를 해결하기 위해 아파치 녹스, 아파치 센트리, 아파치 레인저, 커베로스 등을 활용할 수 있다. 이를 간단하게 하나씩 알아보자.

아파치 녹스는 외부 클라이언트가 하둡 에코시스템에 직접 접근하는 것을 막고, 항상 녹스를 거쳐 통신하게 하는 중간 게이트웨이 역할로 주로 사용된다.

아파치 센트리는 하둡 파일시스템에 상세한 접근 제어를 할 때 사용된다. 아파치 녹스는 하둡 자체에 대한 접근보안이라면 아파치 센트리는 그 안에서의 상세한 접근을 관리하는 것 같다.

아파치 레인저는 아파치 녹스와 같은 기능을 하는데, 레인저가 지원하는 에코시스템이 더 많아 범용성이 좀 더 높은 편이다.

커베로스는 하둡 파일시스템에 접근하려는 클라이언트 에코시스템이 AS 인증 서버를 통해 인증을 수행하고 TGS 티켓 발행 서버로부터 하둡 파일시스템에 접근을 허용하는 티켓을 발행받게해서 유효한 티켓만 있다면 하둡 파일시스템에 인증없이 접근할 수 있게 해준다.