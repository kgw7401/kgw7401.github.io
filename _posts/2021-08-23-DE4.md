---
title: "데이터 엔지니어링(4) - 빅데이터 수집"
excerpt: ""

categories:
  - Data Engineering
tags:
  - 데이터 엔지니어링 기초
toc: true
toc_label: "목차"
published: false
---

# 빅데이터 수집

## 빅데이터 수집 개요

빅데이터 시스템 구축은 수집에서부터 시작한다. 수집은 모든 절차 중 절반 이상을 차지할 정도로 굉장히 중요한데, 크게 **내부 데이터(고객정보, 거래정보...)**와 **외부 데이터(SNS, 뉴스/날씨, 기관 지표...)**까지 굉장히 광범위하다. 

수집 프로세스는 크게 **수집 대상 선정 -> 수집 계획 수립 -> 수집 실행**로 이루어져 있고, 수집 실행에서 업무요건과 환경의 변화로 다시 수집 계획 수립 단계로 되돌아가는 경우가 빈번하다. 

<img src="https://drive.google.com/uc?export=view&id=1wpL45TNcxx2Eyl0dmroTc4k1ackcbfeV">

예전에는 수집/적재 후, 맵리듀스 기반의 주기적인 배치성 분석을 수행하는 것이었으나 이제는 수집과 동시에 분석을 수행하는 ESP/CEP 기술들이 빅데이터의 수집 영역에 적용되고 있는 추세이다. 

## 빅데이터 수집에 활용할 기술

### 플럼

#### 플럼 소개

플럼은 빅데이터를 수집할 때 다양한 수집 요구사항들을 해결하기 위한 기능으로 구성된 소프트웨어다. 데이터를 수집할 때 통신 프로토콜, 메시지 포맷, 발생 주기, 데이터 크기 등으로 많은 고민을 하게 되는데, 플럼은 이러한 문제를 쉽게 해결할 수 있게 해주었다.

#### 플럼 아키텍처

플럼은 크게 **Source, Channel, Sink** 3단계를 활용한다. Source에서 데이터를 로드하고, Channel에서 데이터를 임시 저장해 놓았다가, Sink를 통해 목적지에 데이터를 최종 적재한다. 위와 같은 메커니즘을 Agent라고 부른다.

<img src="https://drive.google.com/uc?export=view&id=1HSa1e9fpokLxpk52K_59BWe9pkxnhBWA">

또한 Interceptor를 추가해 데이터를 가공할 수도 있다.

<img src="https://drive.google.com/uc?export=view&id=1ccCOegrBnNGTORW2bpsUMxwgO5Dqt_Iv">

이 밖에도 다양한 아키텍처가 있는데, 한 개의 에이전트 안에서 두 개 이상의 Source-Channel-Sink 컴포넌트를 구성할 수도 있고 성능과 안정성을 위해 분산 아키텍처를 이용할 수도 있다.

아직까지는 조금 이해하기 힘든 내용이므로 너무 깊게는 이해하려 하지 말고 나중에 직접 실습을 해보면서 알아가보도록 하자.

#### 플럼 활용 방안

이번 스마트카 분석에서 플럼은 100대의 스마트카에서 매일 매일 발생하는 상태 정보 로그를 수집하여 하둡에 적재하고 향후 대규모 배치 분석에 활용한다.

또한 실시간으로 발생하는 운행 정보를 발생과 동시에 플럼 에이전트가 수집해서 카프카에 전송한다.

### 카프카

#### 카프카 소개

카프카는 MOM 소프트웨어 중 하나로 대규모로 발생하는 메세지성 데이터를 비동기 방식으로 중계하는 역할을 한다.대규모 트랜잭션 데이터가 발생했을 때 중간에서 데이터를 버퍼링하면서 타깃 시스템에 안정적으로 전송해주는 중간 시스템을 맡는다.

#### 카프카 아키텍처

클러스터 방식에 따라 **싱글 브로커/싱글 노드, 멀티 브로커/싱글 노드, 멀티 브로커/멀티 노드** 3가지 아키텍처 구성이 가능하며, 이때 반드시 주키퍼를 이용해야 한다.

<img src="https://drive.google.com/uc?export=view&id=1iCsXMaVH7aHO5aVRK7j7kazppFg54hW4">

싱글 브로커/싱글 노드는 대량의 발행/소비 요건이 없고 업무 도메인이 단순할 때 사용하고, 멀티 브로커/싱글 노드는 업무 도메인이 복잡해서 메시지 처리를 분리 관리할 때 사용한다. 마지막으로 멀티 브로커/멀티 노드는 대규모 발행/소비 데이터 처리에 적합하며, 업무 도메인별 메세지 그룹을 분류할 수도 있어 복잡한 메시지 송/수신에 활용하면 적합하다.

#### 카프카 활용 방안

이번 프로젝트에서 카프카의 역할은 플럼이 실시간 데이터를 수집하면 카프카 토픽에 전송하고, 이 데이터를 임시로 저장하고 있다가 컨슈머 프로그램이 작동해 토픽에서 데이터를 가져간다.

1초 간격으로 데이터가 발생하면 플럼에게는 수집이 굉장히 부담스럽다. 이때 카프카가 완충 역할을 함으로써 안정적인 수집 아키텍처를 구성할 수 있다. 

## 수집 파일럿 실행 1단계 - 수집 아키텍처

### 요구 사항 구체화 및 분석

| 수집 요구사항 구체화 | 분석 및 해결방안 |
| ------------------- | --------------- |
| 1. 스마트카로부터 로그 파일들이 주기적으로 발생한다. | 플럼을 이용해 대용량 배치 파일 및 실시간 로그 파일을 수집 |
| 2. 스마트카의 배치 로그 이벤트를 감지해야 한다. | 플럼의 Source 컴포넌트 중 SpoolDir를 이용해 주기적인 로그 파일 발생 이벤트를 감지 |
| 3. 스마트카의 실시간 로그 발생 이벤트를 감지해야 한다. | 플럼의 Source 컴포넌트 중 Exec-Tail을 이용해 특정 로그 파일에서 로그 생성 이벤트를 감지 |
| 4. 스마트카가 만들어내는 로그 데이터에 가비지 데이터가 있을 수 있다. | 플럼의 Interceptor를 이용해 정상 패턴의 데이터만 필터링 |
| 5. 수집 도중 장애가 발생해도 데이터를 안전하게 보관 및 재처리할 수 있어야 한다. | 플럼의 메모리 Channel 및 카프카 Broker 사용으로 로컬 디스크의 파일 시스템에 수집 데이터를 임시 저장 |
| 6. 스마트카의 실시간 로그 파일은 비동기 처리로 빠른 수집 처리를 해야 한다. | 플럼에서 수집한 데이터를 카프카 Sink 컴포넌트를 이용해 카프카 Topic에 비동기 전송 |

<img src="https://drive.google.com/uc?export=view&id=1fSx7zjQOz4nnlhYUbfSPKiKKpvcr4VSY">

## 수집 파일럿 실행 2단계 - 수집 환경 구성