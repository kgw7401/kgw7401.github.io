---
title: "데이터 엔지니어링(4) - 빅데이터 수집"
excerpt: ""

categories:
  - Data Engineering
tags:
  - 데이터 엔지니어링 기초
toc: true
toc_label: "목차"
published: false
---

# 빅데이터 수집

## 빅데이터 수집 개요

빅데이터 시스템 구축은 수집에서부터 시작한다. 수집은 모든 절차 중 절반 이상을 차지할 정도로 굉장히 중요한데, 크게 **내부 데이터(고객정보, 거래정보...)**와 **외부 데이터(SNS, 뉴스/날씨, 기관 지표...)**까지 굉장히 광범위하다. 

수집 프로세스는 크게 **수집 대상 선정 -> 수집 계획 수립 -> 수집 실행**로 이루어져 있고, 수집 실행에서 업무요건과 환경의 변화로 다시 수집 계획 수립 단계로 되돌아가는 경우가 빈번하다. 

<img src="https://drive.google.com/uc?export=view&id=1wpL45TNcxx2Eyl0dmroTc4k1ackcbfeV">

예전에는 수집/적재 후, 맵리듀스 기반의 주기적인 배치성 분석을 수행하는 것이었으나 이제는 수집과 동시에 분석을 수행하는 ESP/CEP 기술들이 빅데이터의 수집 영역에 적용되고 있는 추세이다. 

## 빅데이터 수집에 활용할 기술

### 플럼

#### 플럼 소개

플럼은 빅데이터를 수집할 때 다양한 수집 요구사항들을 해결하기 위한 기능으로 구성된 소프트웨어다. 데이터를 수집할 때 통신 프로토콜, 메시지 포맷, 발생 주기, 데이터 크기 등으로 많은 고민을 하게 되는데, 플럼은 이러한 문제를 쉽게 해결할 수 있게 해주었다.

#### 플럼 아키텍처

플럼은 크게 **Source, Channel, Sink** 3단계를 활용한다. Source에서 데이터를 로드하고, Channel에서 데이터를 임시 저장해 놓았다가, Sink를 통해 목적지에 데이터를 최종 적재한다. 위와 같은 메커니즘을 Agent라고 부른다.

<img src="https://drive.google.com/uc?export=view&id=1HSa1e9fpokLxpk52K_59BWe9pkxnhBWA">

또한 Interceptor를 추가해 데이터를 가공할 수도 있다.

<img src="https://drive.google.com/uc?export=view&id=1ccCOegrBnNGTORW2bpsUMxwgO5Dqt_Iv">

이 밖에도 다양한 아키텍처가 있는데, 한 개의 에이전트 안에서 두 개 이상의 Source-Channel-Sink 컴포넌트를 구성할 수도 있고 성능과 안정성을 위해 분산 아키텍처를 이용할 수도 있다.

아직까지는 조금 이해하기 힘든 내용이므로 너무 깊게는 이해하려 하지 말고 나중에 직접 실습을 해보면서 알아가보도록 하자.

#### 플럼 활용 방안

이번 스마트카 분석에서 플럼은 100대의 스마트카에서 매일 매일 발생하는 상태 정보 로그를 수집하여 하둡에 적재하고 향후 대규모 배치 분석에 활용한다.

또한 실시간으로 발생하는 운행 정보를 발생과 동시에 플럼 에이전트가 수집해서 카프카에 전송한다.

### 카프카

#### 카프카 소개

카프카는 MOM 소프트웨어 중 하나로 대규모로 발생하는 메세지성 데이터를 비동기 방식으로 중계하는 역할을 한다.대규모 트랜잭션 데이터가 발생했을 때 중간에서 데이터를 버퍼링하면서 타깃 시스템에 안정적으로 전송해주는 중간 시스템을 맡는다.

#### 카프카 아키텍처

클러스터 방식에 따라 **싱글 브로커/싱글 노드, 멀티 브로커/싱글 노드, 멀티 브로커/멀티 노드** 3가지 아키텍처 구성이 가능하며, 이때 반드시 주키퍼를 이용해야 한다.

<img src="https://drive.google.com/uc?export=view&id=1iCsXMaVH7aHO5aVRK7j7kazppFg54hW4">

싱글 브로커/싱글 노드는 대량의 발행/소비 요건이 없고 업무 도메인이 단순할 때 사용하고, 멀티 브로커/싱글 노드는 업무 도메인이 복잡해서 메시지 처리를 분리 관리할 때 사용한다. 마지막으로 멀티 브로커/멀티 노드는 대규모 발행/소비 데이터 처리에 적합하며, 업무 도메인별 메세지 그룹을 분류할 수도 있어 복잡한 메시지 송/수신에 활용하면 적합하다.

#### 카프카 활용 방안

이번 프로젝트에서 카프카의 역할은 플럼이 실시간 데이터를 수집하면 카프카 토픽에 전송하고, 이 데이터를 임시로 저장하고 있다가 컨슈머 프로그램이 작동해 토픽에서 데이터를 가져간다.

1초 간격으로 데이터가 발생하면 플럼에게는 수집이 굉장히 부담스럽다. 이때 카프카가 완충 역할을 함으로써 안정적인 수집 아키텍처를 구성할 수 있다. 

## 수집 파일럿 실행 1단계 - 수집 아키텍처

### 요구 사항 구체화 및 분석

| 수집 요구사항 구체화 | 분석 및 해결방안 |
| ------------------- | --------------- |
| 1. 스마트카로부터 로그 파일들이 주기적으로 발생한다. | 플럼을 이용해 대용량 배치 파일 및 실시간 로그 파일을 수집 |
| 2. 스마트카의 배치 로그 이벤트를 감지해야 한다. | 플럼의 Source 컴포넌트 중 SpoolDir를 이용해 주기적인 로그 파일 발생 이벤트를 감지 |
| 3. 스마트카의 실시간 로그 발생 이벤트를 감지해야 한다. | 플럼의 Source 컴포넌트 중 Exec-Tail을 이용해 특정 로그 파일에서 로그 생성 이벤트를 감지 |
| 4. 스마트카가 만들어내는 로그 데이터에 가비지 데이터가 있을 수 있다. | 플럼의 Interceptor를 이용해 정상 패턴의 데이터만 필터링 |
| 5. 수집 도중 장애가 발생해도 데이터를 안전하게 보관 및 재처리할 수 있어야 한다. | 플럼의 메모리 Channel 및 카프카 Broker 사용으로 로컬 디스크의 파일 시스템에 수집 데이터를 임시 저장 |
| 6. 스마트카의 실시간 로그 파일은 비동기 처리로 빠른 수집 처리를 해야 한다. | 플럼에서 수집한 데이터를 카프카 Sink 컴포넌트를 이용해 카프카 Topic에 비동기 전송 |

<img src="https://drive.google.com/uc?export=view&id=1fSx7zjQOz4nnlhYUbfSPKiKKpvcr4VSY">

## 수집 파일럿 실행 2단계 - 수집 환경 구성

이제 본격적으로 수집 환경을 구성해보도록 하자. CM을 이용해 플럼과 카프카를 Server 가상 머신에 설치한다.

### 플럼 설치

1. CM의 클러스터에 `서비스 추가`를 클릭해 Flume을 선택하고 `계속`을 클릭한다. 

2. 플럼을 설치할 서버 호스트를 `server02.hadoop.com`으로 선택하고 `계속`을 클릭한다.

<img src="">

3. 그러면 server02에 성공적으로 플럼이 설치가 된다.

4. 플럼의 Default 그룹의 Heap Memory가 너무 작게 설정되어 있으므로 메모리 용량을 50Mb에서 100Mb로 키운다.

<img src="">

5. 플럼의 콤보박스를 클릭하여 `시작`을 클릭하면 플럼을 실행할 수 있다.

### 카프카 설치

1. 카프카 또한 플럼과 설치과정이 비슷하다. 먼저 `서비스 추가`를 통해 카프카를 선택한다.

2. 서버 호스트를 `server02.hadoop.com`로 지정하고 나머지는 지정하지 않는다.

<img src="">

3. 카프카의 Default를 그대로 유지하고 `계속`을 클릭해 카프카 설치를 끝낸다.

4. 카프카의 Default 그룹의 Data Retension Time을 7일에서 10분으로 줄인다.

## 수집 파일럿 실행 3단계 - 플럼 수집 기능 구현

플럼에서는 2개의 에이전트를 구현한다. 스마트카 상태 정보와 운전자 운행 정보가 그것이다. 플럼의 에이전트를 만들려면 플럼이 인식할 수 있는 특정 디렉터리에 이름이 `{ Agent 고유이름 }.conf` 형식인 파일을 생성하면 된다.

### SmartCar 에이전트 생성

플럼의 `구성`에서 `Agent 이름`을 SmartCar_Agent로 지정한다. 그리고 `구성 파일` 부분을 다음과 같은 내용으로 다시 채워넣는다. 

```
SmartCar_Agent.sources  = SmartCarInfo_SpoolSource
SmartCar_Agent.channels = SmartCarInfo_Channel
SmartCar_Agent.sinks    = SmartCarInfo_LoggerSink 

SmartCar_Agent.sources.SmartCarInfo_SpoolSource.type = spooldir
SmartCar_Agent.sources.SmartCarInfo_SpoolSource.spoolDir = /home/pilot-pjt/working/car-batch-log
SmartCar_Agent.sources.SmartCarInfo_SpoolSource.deletePolicy = immediate
SmartCar_Agent.sources.SmartCarInfo_SpoolSource.batchSize = 1000


SmartCar_Agent.channels.SmartCarInfo_Channel.type = memory
SmartCar_Agent.channels.SmartCarInfo_Channel.capacity  = 100000
SmartCar_Agent.channels.SmartCarInfo_Channel.transactionCapacity  = 10000


SmartCar_Agent.sinks.SmartCarInfo_LoggerSink.type = logger

SmartCar_Agent.sources.SmartCarInfo_SpoolSource.channels = SmartCarInfo_Channel
SmartCar_Agent.sinks.SmartCarInfo_LoggerSink.channel = SmartCarInfo_Channel
```

총 5개의 단락으로 구분되어 있는데, 첫번째부터 하나 씩 살펴보도록 하자. 

① 플럼의 에이전트에서 사용할 Source, Channel, Sink의 각 리소스 변수를 정의한 것이다.
② 에이전트의 Source를 설정한다. Type을 "spooldir"로 설정한다. "spooldir"는 지정한 특정 디렉터리를 모니터링하고 있다가 새로운 파일이 생성되면 이벤트를 감지해서 "batchSize"만큼 Channel에 전송한다
③ 에이전트의 Channel로서 type을 "Memory"로 설정했다. 종류는 크게 memory와 file이 있다. memory는 받은 메모리를 메모리상에 중간 적재하므로 성능이 높지만 안정성이 낮다. file은 로컬 파일시스템 경로인 dataDirs에 임시로 저장했다가 Sink에게 제공하므로 성능은 낮지만 안정성이 높다.
④ 에이전트의 최종 목적지이다. Type을 "logger"로 설정했다. 수집한 데이터를 테스트 및 디버깅 목적으로 `/var/log/flume-ng/flume-cmf-flume-AGENT-server02.hadoop.com.log`에 출력한다.
⑤ Source와 Channel Sink를 연결한다. 채널값을 SmartCarInfo_Channel로 설정하여 File -> Channel -> Sink로 이어지는 에이전트 리소스를 하나로 연결해 준다.(사실 무슨 소린지 잘 모르겠다 ㅠㅠ)

### SmartCar 에이전트에 Interceptor 추가

Interceptor는 Source와 Channel 중간에서 데이터를 가공하는 역할을 한다. 플럼에서 데이터 전송 단위를 Event라고 하는데, 이는 다시 Header와 Body로 구성된다. 이때 Interceptor는 Header에 특정값을 추가하거나 Body에 데이터를 가공하는 기능으로 활용된다.

```
SmartCar_Agent.sources  = SmartCarInfo_SpoolSource
SmartCar_Agent.channels = SmartCarInfo_Channel
SmartCar_Agent.sinks    = SmartCarInfo_LoggerSink 

SmartCar_Agent.sources.SmartCarInfo_SpoolSource.type = spooldir
SmartCar_Agent.sources.SmartCarInfo_SpoolSource.spoolDir = /home/pilot-pjt/working/car-batch-log
SmartCar_Agent.sources.SmartCarInfo_SpoolSource.deletePolicy = immediate
SmartCar_Agent.sources.SmartCarInfo_SpoolSource.batchSize = 1000

----------------------------------------------------------------------------------
SmartCar_Agent.sources.SmartCarInfo_SpoolSource.interceptors = filterInterceptor

SmartCar_Agent.sources.SmartCarInfo_SpoolSource.interceptors.filterInterceptor.type = regex_filter
SmartCar_Agent.sources.SmartCarInfo_SpoolSource.interceptors.filterInterceptor.regex = ^\\d{14}
SmartCar_Agent.sources.SmartCarInfo_SpoolSource.interceptors.filterInterceptor.excludeEvents = false
----------------------------------------------------------------------------------

SmartCar_Agent.channels.SmartCarInfo_Channel.type = memory
SmartCar_Agent.channels.SmartCarInfo_Channel.capacity  = 100000
SmartCar_Agent.channels.SmartCarInfo_Channel.transactionCapacity  = 10000


SmartCar_Agent.sinks.SmartCarInfo_LoggerSink.type = logger

SmartCar_Agent.sources.SmartCarInfo_SpoolSource.channels = SmartCarInfo_Channel
SmartCar_Agent.sinks.SmartCarInfo_LoggerSink.channel = SmartCarInfo_Channel
```

Interceptor가 추가됨으로써 플럼 에이전트가 조금 복잡해졌다.

① 수집 데이터를 필터링하기 위해 filterInterceptor를 선언했다.
② 정규 표현식을 이용해 수집 데이터를 필터링한다. 여기서는 `^\\d{14}`를 통해 \로 시작하는 14자리 숫자형식만 받게 설정하였다. `excludeEvents = False`는 포함한다는 뜻이다. 

### DriverCarInfo 에이전트 생성

```
SmartCar_Agent.sources  = SmartCarInfo_SpoolSource DriverCarInfo_TailSource
SmartCar_Agent.channels = SmartCarInfo_Channel DriverCarInfo_Channel
SmartCar_Agent.sinks    = SmartCarInfo_LoggerSink DriverCarInfo_KafkaSink

SmartCar_Agent.sources.SmartCarInfo_SpoolSource.type = spooldir
SmartCar_Agent.sources.SmartCarInfo_SpoolSource.spoolDir = /home/pilot-pjt/working/car-batch-log
SmartCar_Agent.sources.SmartCarInfo_SpoolSource.deletePolicy = immediate
SmartCar_Agent.sources.SmartCarInfo_SpoolSource.batchSize = 1000

SmartCar_Agent.sources.SmartCarInfo_SpoolSource.interceptors = filterInterceptor

SmartCar_Agent.sources.SmartCarInfo_SpoolSource.interceptors.filterInterceptor.type = regex_filter
SmartCar_Agent.sources.SmartCarInfo_SpoolSource.interceptors.filterInterceptor.regex = ^\\d{14}
SmartCar_Agent.sources.SmartCarInfo_SpoolSource.interceptors.filterInterceptor.excludeEvents = false


SmartCar_Agent.channels.SmartCarInfo_Channel.type = memory
SmartCar_Agent.channels.SmartCarInfo_Channel.capacity  = 100000
SmartCar_Agent.channels.SmartCarInfo_Channel.transactionCapacity  = 10000


SmartCar_Agent.sinks.SmartCarInfo_LoggerSink.type = logger

SmartCar_Agent.sources.SmartCarInfo_SpoolSource.channels = SmartCarInfo_Channel
SmartCar_Agent.sinks.SmartCarInfo_LoggerSink.channel = SmartCarInfo_Channel

----------------------------------------------------------------------------------

SmartCar_Agent.sources.DriverCarInfo_TailSource.type = exec
SmartCar_Agent.sources.DriverCarInfo_TailSource.command = tail -F /home/pilot-pjt/working/driver-realtime-log/SmartCarDriverInfo.log
SmartCar_Agent.sources.DriverCarInfo_TailSource.restart = true
SmartCar_Agent.sources.DriverCarInfo_TailSource.batchSize = 1000

SmartCar_Agent.sources.DriverCarInfo_TailSource.interceptors = filterInterceptor2

SmartCar_Agent.sources.DriverCarInfo_TailSource.interceptors.filterInterceptor2.type = regex_filter
SmartCar_Agent.sources.DriverCarInfo_TailSource.interceptors.filterInterceptor2.regex = ^\\d{14}
SmartCar_Agent.sources.DriverCarInfo_TailSource.interceptors.filterInterceptor2.excludeEvents = false

SmartCar_Agent.sinks.DriverCarInfo_KafkaSink.type = org.apache.flume.sink.kafka.KafkaSink
SmartCar_Agent.sinks.DriverCarInfo_KafkaSink.topic = SmartCar-Topic
SmartCar_Agent.sinks.DriverCarInfo_KafkaSink.brokerList = server02.hadoop.com:9092
SmartCar_Agent.sinks.DriverCarInfo_KafkaSink.requiredAcks = 1
SmartCar_Agent.sinks.DriverCarInfo_KafkaSink.batchSize = 1000


SmartCar_Agent.channels.DriverCarInfo_Channel.type = memory
SmartCar_Agent.channels.DriverCarInfo_Channel.capacity= 100000
SmartCar_Agent.channels.DriverCarInfo_Channel.transactionCapacity = 10000


SmartCar_Agent.sources.DriverCarInfo_TailSource.channels = DriverCarInfo_Channel
SmartCar_Agent.sinks.DriverCarInfo_KafkaSink.channel = DriverCarInfo_Channel
```

기존 구성 파일에 위와 같은 내용을 추가한다. SmartCarInfo와 거의 유사한데 살짝 다른 점은 Source의 Type이 "exec"다. 이는 플럼 외부에서 수행한 명령의 결과를 플럼의 Event로 가져와 수집할 수 있는 기능을 제공한다. 

## 수집 파일럿 실행 4단계 - 카프카 기능 구현

카프카의 명령어를 사용해 카프카의 브로커 안에 앞으로 사용하게 될 토픽을 생성하고, 카프카의 Producer 명령어를 통해 토픽에 데이터를 전송한다. 토픽으로 들어간 데이터를 다시 카프카의 Consumer 명령어로 수신한다.

### 카프카 Topic 생성

Server02에서는 카프카의 CLI 명령어를 이용해 다양한 카프카 기능을 사용해 볼 수 있다. `kafka-topics --create --zookeeper server02.hadoop.com:2181 --replication-factor 1 --partitions 1 --topic SmartCar-Topic` 명령어로 SmartCar-Topic 토픽을 생성한다.

<img src="">

### 카프카 Producer 사용

`kafka-console-producer --broker-list server02.hadoop.com:9092 -topic SmartCar-Topic` 명령어를 입력하고 "Hello! BigData!"라는 메시지를 입력해서 에러가 없으면 성공적으로 전송이 된 것이다. 

앞서 Producer가 전송한 메시지는 아직 카프카 토픽에 머물러 있는 상태이다. Concumer 콘솔을 실행해서 SmartCar-Topic에 연결하면 "Hello! BigData!" 메시지를 수신받게 될 것이다. 

### 카프카 Consumer 사용

새로 SSH 터미널을 2개 열어서 각각에 아래의 카프카 Consumer 명령을 실행한다.
`kafka-console-consumer --bootstrap-server server02.hadoop.com:9092 --topic SmartCar-Topic --partition 0 --from-beginning` 

두 개의 터미널 모두 "Hello! BigData!"가 출력되는 것을 볼 수 있다. 

<img src="">

## 수집 파일럿 실행 5단계 - 수집 기능 테스트

지금까지 구성한 수집 기능이 정상적으로 작동하는지 간단하게 살펴보자.

1\. server02에 접속하고 `bigdata.smartcar.loggen-1.0.jar`가 위치한 곳으로 이동한다.
```linux
cd /home/pilot-pjt/working
```

2\. 스마트카 로그 시뮬레이터를 백그라운드 방식으로 실행한다.

```linux
java -cp bigdata.smartcar.loggen-1.0.jar com.wikibook.bigdata.smartcar.loggen.CarLogMain 20160101 3 &

java -cp bigdata.smartcar.loggen-1.0.jar com.wikibook.bigdata.smartcar.loggen.DriverLogMain 20160101 3 &
```