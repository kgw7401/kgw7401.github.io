---
title: "빅데이터를 지탱하는 기술(3) - 빅데이터의 분산 처리"
excerpt: ""

categories:
  - Book
  - Data Engineering
tags:
  - Book
  - Data Engineering 기초
toc: true
toc_label: "목차"
published: false
---

# 3. 빅데이터의 분산 처리

## 3.1 대규모 분산 처리의 프레임워크

### 구조화 데이터와 비구조화 데이터

SQL로 데이터를 집계하는 경우, 테이블이 명확하게 정의되어 있는 구조화된 데이터를 사용한다. 기존의 데이터 웨어하우스에서 데이터는 항상 구조화된 데이터로 축적하는 것이 일반적이었다.

하지만 텍스트, 이미지, 동영상 등의 구조화되지 않은 비구조화 데이터도 점차 늘어나 SQL로 제대로 집계할 수 없게 된다.

비구조화 데이터를 분산 스토리지 등에 저장하고 그것을 분산 시스템에서 처리하는 것이 데이터 레이크의 개념이다. 이 경우는 데이터를 가공하는 과정에서 스키마를 정의하고, 구조화된 데이터로 변환한다.

#### 스키마리스 데이터: 기본 서식은 있지만, 스키마가 정의 안 됨.

CSV, JSON, XML 등의 데이터는 서식은 정해져 있지만, 칼럼 수나 데이터형은 명확하지 않아, **스키마리스 데이터**라고 한다. 최근에는 JSON 형식을 이용하는 경우가 많고, 일일이 스키마를 정하는 것은 시간과 비용이 소모되기 때문에 JSON은 JSON 그대로 저장하고 거기서 데이터 분석에 필요한 필드만을 추출하는 편이 간단하다. 

#### 데이터 구조화의 파이프라인

<img src="">

기본적인 데이터 파이프라인은 다음과 같다. 각 데이터 소스에서 수집된 비구조화 데이터, 또는 스키마리스 데이터는 처음에는 분산 스토리지에 보존된다. 이는 SQL로 집계할 수 없다. 따라서 스키마를 명확하게 하는 구조화 데이터로 변환해야 한다. 

일반적으로 구조화 데이터는 압축율을 높이기 위해 열 지향 스토리지로 저장한다. 이 중 시간에 따라 증가하는 데이터를 팩트 테이블, 그에 따른 부속 데이터를 디멘전 테이블로 취급한다. 

#### 열 지향 스토리지의 작성

MPP 데이터베이스의 경우, 제품에 따라 스토리지의 형식이 고정되어 있어 사용자가 그 상세를 몰라도 괜찮지만, Hadoop에서는 사용자가 직접 열 지향 스토리지의 형식을 선택하고, 자신이 좋아하는 쿼리 엔진에서 그것을 집계할 수 있다.

Hadoop에서 사용할 수 있는 열 지향 스토리지에는 몇 가지 종류가 있다. Apache ORC는 구조화 데이터를 위한 열 지향 스토리지로 처음에 스키마를 정한 후 데이터를 저장한다. 반면 Apache Parquet은 스키마리스에 가까운 구조로 되어 있어 JSON 같은 뒤얽힌 데이터도 그대로 저장할 수 있다. 

비구조화 데이터를 읽어들여 열 지향 스토리지로 변환하는 과정에서는 컴퓨터 리소스가 많이 소비된다. 그래서 사용되는 것이 Hadoop과 Spark와 같은 분산 처리 프레임워크이다. 

### Hadoop: 분산 데이터 처리의 공통 플랫폼

Hadoop은 단일 소프트웨어가 아니라 분산 시스템을 구성하는 다수의 소프트웨어로 이루어진 집합체이다. 

<img src="">

#### 분산 시스템의 기본 구성 요소: HDFS, YARN, MapReduce

Hadoop의 기본 구성 요소는 **분산 파일 시스템인 "HDFS"**, **리소스 관리자 "YARN"**, 그리고 **분산 데이터 처리의 기반인 "MapReduce"** 이 3가지이다. 이는 Hadoop의 기반이라고 얘기할 수도 있다. 

위처럼 Hadoop에 의존하는 것이 아니라, 일부만 사용하거나 혹은 전혀 이용하지 않는 구성도 있다. 예를 들어, 분산 파일 시스템으로는 HDFS, 리소스 관리자는 Mesos, 분산 데이터 처리에는 Spark를 사용하는 구성도 가능하다. 

#### 분산 파일 시스템과 리소스 관리자: HDFS, YARN

Hadoop에서 처리되는 데이터 대부분은 분산 파일 시스템인 HDFS에 저장된다. 이것은 네트워크에 연결된 파일 서버와 같은 존재이지만, 다수의 컴퓨터에 파일을 복사하여 중복성을 높인다는 특징이 있다.

YARN(Yet Another Resource Negotiator)은 CPU나 메모리 등의 계산 리소스 매니저 역할을 한다. YARN은 애플리케이션이 사용하는 CPU 코어와 메모리를 컨테이너라고 불리는 단위로 관리한다. 리소스 매니저는 어느 애플리케이션에 얼마만큼의 리소스를 할당할 지 관리함으로써 모든 애플리케이션이 차질없이 실행되도록 제어한다.

#### 분산 데이터 처리 및 쿼리 엔진: MapReduce, Hive

MapReduce는 YARN 상에서 동작하는 분산 애플리케이션 중 하나이며, 분산 시스템에서 데이터 처리를 실행하는 데 사용된다. 이는 임의의 자바 프로그램을 실행기킬 수 있기 때문에 비구조화 데이터를 가공하는 데 적합하다.

한편, SQL 등의 쿼리 언어에 의한 데이터 집계가 목적이라면 Hive를 이용한다. 이는 쿼리를 자동으로 MapReduce 프로그램으로 변환하는 소프트웨어로 개발되었다. 

MapReduce는 대량의 데이터를 배치 처리하기 위한 시스템이므로, 작은 프로그램을 실행하려면 오버헤드(어떤 처리를 하기 위해 들어가는 간접적인 처리 시간, 메모리 등을 말한다.)가 너무 크기 때문에 몇 초 밖에 안 걸리는 쿼리 실행에는 적합하지 않다. Hive도 MapReduce의 성질을 계승하고 있기 때문에 마찬가지이다. 애드 혹 쿼에는 부적합하다. 

#### Hive on Tez

Hive를 가속화하기 위해 개발된 것이 Tez이다. Tez는 기존의 MapReduce를 대체할 목적으로 개발되어 고속화를 실현하고 있다. 현재의 Hive는 Tez를 사용해도 동작하게 구성되어 있어 Hive on Tez라고 불린다. 

#### 대화형 쿼리 엔진: Impala, Presto

Hive를 고속화하는 것이 아니라 처음부터 대화형의 쿼리 실행만 전문으로 하는 쿼리 엔진도 개발되고 있다. Impala와 Presto가 대표적이다.

대화형 쿼리 엔진은 순간 최대 속도를 높이기 위해 모든 오버헤드가 제거되어 사용할 수 있는 리소스를 최대한 활용하여 쿼리를 실행한다. 

Hadoop에서는 이와 같이 성질이 다른 쿼리 엔진을 목적에 따라 구분한다. 대량의 비구조화 데이터를 가공하는 무거운 배치 처리에는 높은 처리량으로 리소스를 활용할 수 있는 Hive를, 그렇게 해서 완성한 구조화 데이터를 대화식으로 집계하고자 할 때는 Impala와 Presto를 사용한다. 

### Spark

Spark는 MapReduce보다 더 효율적인 데이터 처리를 실현하기 위한 도구이다. 이는 Tez와 달리 Hadoop과는 다른 독립된 프로젝트이다.

Spark의 특징은 대량의 메모리를 활용하여 고속화를 실현한다는 것이다. MapReduce는 데이터 처리의 대부분을 디스크의 읽고 쓰기에 사용하였다. 그러나 메모리의 양이 증가함에 따라, 디스크에서 읽고 쓰는 것이 아니라 가능한 많은 데이터를 메모리상에 올린 상태로 두어 디스크에는 아무것도 기록하지 않는다는 선택이 현실화되었다. 이 경우 컴퓨터가 비정산 종료하면 중간까지 처리한 중간 데이터는 사라지지만, 그때는 처리를 다시 시도해서 중간 데이터를 다시 만들면 된다는 것이 Spark의 기본 개념이다. 

#### MapReduce를 대체하는 Spark의 입지

Spark는 Hadoop의 대체제가 아니라 MapReduce의 대체제이다. HDFS나 YARN 등은 Spark에서 그대로 사용할 수 있다. 반대로 Hadoop을 이용하지 않고 분산 스토리지로 Amazon S3, 분산 데이터베이스로 카산드라를 이용할 수도 있다. 

또한 Spark는 자바, 스칼라, 파이썬, R 등 다양한 스크립트 언어를 사용하여 데이터 처리를 할 수 있고, 문서도 충실하기 때문에 도입이 쉽다. 

그리고 SQL로 쿼리를 실행하기 위한 Spark SQL과 스트림 처리를 수행하기 위한 Spark Streaming이라는 기능이  포함되어 있다. 따라서 대규모 배치 처리뿐만 아니라, SQL에 의한 대화형 쿼리 실행과 실시간 스트림 처리에 이르기까지 널리 이용되고 있다. 

## 3.2 쿼리 엔진

### 데이터 마트 구축의 파이프라인

Hadoop에 의한 구조화 데이터의 작성과 이를 이용한 쿼리의 실행이 어떤 것인지를 알기 위해, 쿼리 엔진을 사용하여 데이터 마트를 만들기까지의 흐름을 살펴보겠다.

<img src="">